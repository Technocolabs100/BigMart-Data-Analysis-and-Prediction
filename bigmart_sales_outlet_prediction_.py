# -*- coding: utf-8 -*-
"""BigMart Sales Outlet Prediction.

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EB6RXWN2Ckihj0bAba618Th8fgwnx9eS

BigMart-Data-Analysis-and-Prediction
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

sns.set()

raw_data = pd.read_csv('train.csv')

raw_data.shape

raw_data.head()

raw_data.info()

raw_data.describe(include='all')

raw_data.isna().sum()

raw_data.duplicated().any()

raw_data.apply(lambda x: len(x.unique()))

cat_cols = raw_data.select_dtypes(exclude='number').columns.to_list()
num_cols = raw_data.select_dtypes(include='number').columns.to_list()

print('Categorical Columns: ', cat_cols)
print('Numerical Columns: ', num_cols)

for col in cat_cols:
    print('-----------------------------')
    print('Series: ', col)
    print('-----------------------------')
    print(raw_data[col].value_counts())
    print('\n')

clean_data = raw_data.copy()

new_col_names = [col.lower() for col in clean_data.columns]
clean_data.columns = new_col_names

print(clean_data.columns)

clean_data['item_weight'].fillna(clean_data['item_weight'].mean(), inplace=True)
clean_data.isna().sum()

outlet_size_mode_pt = clean_data.pivot_table(values='outlet_size',
                                                      columns='outlet_type',
                                                      aggfunc=lambda x: x.mode())
outlet_size_mode_pt

missing_values = clean_data['outlet_size'].isnull()
clean_data.loc[missing_values, 'outlet_size'] = clean_data.loc[missing_values, 'outlet_type'].apply(lambda x: outlet_size_mode_pt[x].outlet_size)
clean_data.isna().sum()

print('Total of 0s before replace: ', sum(clean_data['item_visibility'] == 0))

clean_data.loc[:,'item_visibility'].replace(to_replace=0,
                                            value=clean_data['item_visibility'].mean(),
                                            inplace=True)

print('Total of 0s after replace: ', sum(clean_data['item_visibility'] == 0))

print(clean_data['item_fat_content'].unique())

clean_data['item_fat_content'].replace({'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular'}, inplace=True)
clean_data['item_fat_content'].value_counts()

clean_data['item_category'] = clean_data['item_identifier'].apply(lambda x: x[:2])
clean_data['item_category'] = clean_data['item_category'].replace({'FD':'Food', 'DR':'Drink', 'NC':'Non-Consumable'})
clean_data['item_category'].value_counts()

clean_data.loc[clean_data['item_category'] == 'Non-Consumable', 'item_fat_content'] = 'No Edible'
clean_data['item_fat_content'].value_counts()

clean_data['outlet_years'] = 2013 - clean_data['outlet_establishment_year']
clean_data['outlet_years']

clean_data.head()

plt.figure(figsize=(5,5))
sns.countplot(x='item_fat_content', data=clean_data)
plt.show()

labels = list(clean_data['item_type'].unique())
chart = sns.countplot(x=clean_data['item_type'])
chart.set_xticklabels(labels=labels, rotation=90)

labels = list(clean_data['outlet_identifier'].unique())
chart = sns.countplot(x=clean_data['outlet_identifier'])
chart.set_xticklabels(labels=labels, rotation=90)

plt.figure(figsize=(5,5))
sns.countplot(x='outlet_size', data=clean_data)
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='outlet_location_type', data=clean_data)
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='item_category', data=clean_data)
plt.show()

clean_data.hist(figsize=(12,8))

plt.figure(figsize=(6,6))
sns.countplot(x='outlet_establishment_year', data=clean_data)
plt.show()

plt.figure(figsize=(6,6))
sns.countplot(x='outlet_years', data=clean_data)
plt.show()

corr_matrix = clean_data.corr()
corr_matrix['item_outlet_sales'].sort_values(ascending=False)

sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')

sns.scatterplot(data=clean_data, x='item_mrp', y='item_outlet_sales')

clean_data.head()

encoder = LabelEncoder()

cols_to_encode = ['item_identifier', 'item_type', 'outlet_identifier']

for col in cols_to_encode:
    clean_data[col] = encoder.fit_transform(clean_data[col])

clean_data = pd.get_dummies(clean_data, columns=['item_fat_content', 'outlet_size', 'outlet_location_type', 'outlet_type', 'item_category'])

clean_data.head()

X = clean_data.drop(columns=['outlet_establishment_year', 'item_outlet_sales'])
y = clean_data['item_outlet_sales']

model_scores = pd.DataFrame(columns=['model', 'rmse', 'r2_score'])

def train_and_evaluate_model(model_name, model, X, y):
    '''
    Create a training pipeline to scale and train the model
    using the input data, then evaluate the model and safe its error
    and score in the scores dataframe.
    '''
    X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.2, random_state=42)

    pipeline = make_pipeline(StandardScaler(), model)

    pipeline.fit(X_train, y_train)

    y_hat = pipeline.predict(X_validate)

    rmse = np.sqrt(mean_squared_error(y_validate, y_hat))
    model_score = r2_score(y_validate, y_hat)

    model_scores.loc[len(model_scores)] = [model_name, rmse, model_score]

    print('----------------------------------')
    print(model_name, ' Report:')
    print('----------------------------------')
    print('RMSE: ', rmse)
    print('R2 Score: ', model_score)

linear_regression_model = LinearRegression()
train_and_evaluate_model('Linear Regression', linear_regression_model, X, y)

ridge_model = Ridge()
train_and_evaluate_model('Ridge', ridge_model, X, y)

lasso_model = Lasso()
train_and_evaluate_model('Lasso', lasso_model, X, y)

svr_model = SVR()
train_and_evaluate_model('SVM', svr_model, X, y)

dtr_model = DecisionTreeRegressor()
train_and_evaluate_model('Decision Tree', dtr_model, X, y)

rfr_model = RandomForestRegressor()
train_and_evaluate_model('Random Forest', rfr_model, X, y)

xgbr_model = XGBRegressor()
train_and_evaluate_model('XGBoost', xgbr_model, X, y)

model_scores

model_pipeline = make_pipeline(StandardScaler(), LinearRegression())
model_pipeline.fit(X, y)

test_data=pd.read_csv('test.csv')
test_data=test_data.loc[test_data['Item_Identifier'] == 'FDW58']
test_data

new_col_names = [col.lower() for col in test_data.columns]
test_data.columns = new_col_names

results = test_data[['item_identifier', 'outlet_identifier']]

test_data['item_weight'].fillna(test_data['item_weight'].mean(), inplace=True)

missing_values = test_data['outlet_size'].isnull()
test_data.loc[missing_values, 'outlet_size'] = test_data.loc[missing_values, 'outlet_type'].apply(lambda x: outlet_size_mode_pt[x].outlet_size)

test_data.loc[:,'item_visibility'].replace(to_replace=0,
                                            value=test_data['item_visibility'].mean(),
                                            inplace=True)

test_data['item_category'] = test_data['item_identifier'].apply(lambda x: x[:2])
test_data['item_category'] = test_data['item_category'].replace({'FD':'Food', 'DR':'Drink', 'NC':'Non-Consumable'})

test_data['outlet_years'] = 2013 - test_data['outlet_establishment_year']

test_data = pd.get_dummies(test_data, columns=['item_fat_content', 'outlet_size', 'outlet_location_type', 'outlet_type', 'item_category'])

test_data['item_identifier'] = test_data['item_identifier'].replace({'FDW58': 1114})
test_data['item_type'] = test_data['item_type'].replace({'Snack Foods': 13})
test_data['outlet_identifier'] = test_data['outlet_identifier'].replace({'OUT049': 9,
                                                                         'OUT017': 2,
                                                                         'OUT018': 3,
                                                                         'OUT046': 8,
                                                                         'OUT045': 7,
                                                                         'OUT027': 5,
                                                                         'OUT019': 4})


test_data['item_fat_content_No Edible'] = 0
test_data['item_fat_content_Regular'] = 0
test_data['outlet_size_High'] = 0
test_data['item_category_Drink'] = 0
test_data['item_category_Non-Consumable'] = 0

test_data = test_data.drop(columns=['outlet_establishment_year'])


test_data = test_data[['item_identifier',
                       'item_weight',
                       'item_visibility',
                       'item_type',
                       'item_mrp',
                       'outlet_identifier',
                       'outlet_years',
                       'item_fat_content_Low Fat',
                       'item_fat_content_No Edible',
                       'item_fat_content_Regular',
                       'outlet_size_High',
                       'outlet_size_Medium',
                       'outlet_size_Small',
                       'outlet_location_type_Tier 1',
                       'outlet_location_type_Tier 2',
                       'outlet_location_type_Tier 3',
                       'outlet_type_Grocery Store',
                       'outlet_type_Supermarket Type1',
                       'outlet_type_Supermarket Type2',
                       'outlet_type_Supermarket Type3',
                       'item_category_Drink',
                       'item_category_Food',
                       'item_category_Non-Consumable']]

y_hat = model_pipeline.predict(test_data)


results['prediction'] = y_hat
results
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [markdown]\n# # **1)Problem Statement**\n\n# %% [markdown]\n# # **2)Hypothesis Generation**\n\n# %% [markdown]\n# # **3)Loading Packages and Data**\n# \n# In this step, we're going to import the necessary libraries and load the dataset into our programming environment.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:27:39.230721Z\",\"iopub.execute_input\":\"2023-07-05T18:27:39.231160Z\",\"iopub.status.idle\":\"2023-07-05T18:27:39.239248Z\",\"shell.execute_reply.started\":\"2023-07-05T18:27:39.231128Z\",\"shell.execute_reply\":\"2023-07-05T18:27:39.238044Z\"}}\n#importing necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder  \nimport seaborn as sns\nimport warnings\nimport ydata_profiling as pp\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# %% [markdown]\n# Now that all the necessary libraries are imported, we proceed to load our training and test datasets. \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:03.585761Z\",\"iopub.execute_input\":\"2023-07-05T18:15:03.586180Z\",\"iopub.status.idle\":\"2023-07-05T18:15:03.634646Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:03.586148Z\",\"shell.execute_reply\":\"2023-07-05T18:15:03.633511Z\"}}\n#loading training dataset\nbigm_train=pd.read_csv(\"../input/big-mart-dataset/Train.csv\")\n#loading test dataset\nbigm_test=pd.read_csv(\"../input/big-mart-dataset/Test.csv\")\n\n# %% [markdown]\n#  # **4)Data Structure and Content**\n# After loading the dataset and before processing it, we need to understand the structure of the data and explore its contents beforehand.\n\n# %% [markdown]\n#  **A- Training dataset**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:06.486483Z\",\"iopub.execute_input\":\"2023-07-05T18:15:06.487149Z\",\"iopub.status.idle\":\"2023-07-05T18:15:06.494172Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:06.487106Z\",\"shell.execute_reply\":\"2023-07-05T18:15:06.493395Z\"}}\n#number of rows and columns in the dataset file\nbigm_train.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:09.126781Z\",\"iopub.execute_input\":\"2023-07-05T18:15:09.127769Z\",\"iopub.status.idle\":\"2023-07-05T18:15:09.159932Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:09.127736Z\",\"shell.execute_reply\":\"2023-07-05T18:15:09.158811Z\"}}\nbigm_train.info()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:12.199488Z\",\"iopub.execute_input\":\"2023-07-05T18:15:12.199870Z\",\"iopub.status.idle\":\"2023-07-05T18:15:12.208520Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:12.199841Z\",\"shell.execute_reply\":\"2023-07-05T18:15:12.207397Z\"}}\nbigm_train.dtypes\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:15.312471Z\",\"iopub.execute_input\":\"2023-07-05T18:15:15.312848Z\",\"iopub.status.idle\":\"2023-07-05T18:15:15.332513Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:15.312818Z\",\"shell.execute_reply\":\"2023-07-05T18:15:15.331318Z\"}}\n#first 5 rows of the dataset\nbigm_train.head()\n\n# %% [markdown]\n#  **B- Test dataset**\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:19.523423Z\",\"iopub.execute_input\":\"2023-07-05T18:15:19.523806Z\",\"iopub.status.idle\":\"2023-07-05T18:15:19.530747Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:19.523777Z\",\"shell.execute_reply\":\"2023-07-05T18:15:19.529563Z\"}}\n#number of rows and columns in the dataset file\nbigm_test.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:21.796656Z\",\"iopub.execute_input\":\"2023-07-05T18:15:21.797093Z\",\"iopub.status.idle\":\"2023-07-05T18:15:21.824731Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:21.797053Z\",\"shell.execute_reply\":\"2023-07-05T18:15:21.823160Z\"}}\nbigm_test.info()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:25.332716Z\",\"iopub.execute_input\":\"2023-07-05T18:15:25.333126Z\",\"iopub.status.idle\":\"2023-07-05T18:15:25.342074Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:25.333092Z\",\"shell.execute_reply\":\"2023-07-05T18:15:25.340978Z\"}}\nbigm_test.dtypes\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:28.645369Z\",\"iopub.execute_input\":\"2023-07-05T18:15:28.645748Z\",\"iopub.status.idle\":\"2023-07-05T18:15:28.662784Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:28.645712Z\",\"shell.execute_reply\":\"2023-07-05T18:15:28.661992Z\"}}\n#first 5 rows of the dataset\nbigm_test.head()\n\n# %% [markdown]\n# Our datasets has 12 columns:\n# \n# •Item_Identifier(Categorical): Id of each item\n# \n# •Item_Weight(Numerical): weight of the product.\n# \n# •Item_Fat_Content(Categorical): fat content in the product.\n# \n# •Item_Visibility: proportion of the store's total display area dedicated to the specific product.\n# \n# •Item_Type(Categorical): indicates to which category the item belongs. \n# \n# •Item_MRP(Numerical): maximum retail price (MRP) of the product.\n# \n# •Outlet_Identifier(Categorical): Id of each store. \n# \n# •Outlet_Establishment_Year(Numerical): The year in which the store was established.\n# \n# •Outlet_Size(Categorical): size of the store. \n# \n# •Outlet_Location_Type(Categorical): indicates in which type of city the store is located .\n# \n# •Outlet_Type (Categorical): type of outlet (grocery store, supermarket, etc.).\n# \n# •Item_Outlet_Sales(Numerical): Our target variable. Indicates the sales of the item in the store.\n# \n\n# %% [markdown]\n# # **5)Exploratory Data Analysis**\n\n# %% [markdown]\n# **Outliers**\n\n# %% [markdown]\n# Let's check for outliers in our dataset.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:15:32.653828Z\",\"iopub.execute_input\":\"2023-07-05T18:15:32.654365Z\",\"iopub.status.idle\":\"2023-07-05T18:15:33.933296Z\",\"shell.execute_reply.started\":\"2023-07-05T18:15:32.654300Z\",\"shell.execute_reply\":\"2023-07-05T18:15:33.932213Z\"}}\nplt.figure(figsize=(10, 8)) \n\nnumerical_features = [feature for feature in bigm_train.columns if bigm_train[feature].dtype != 'object']\nfor feature in numerical_features:\n    \n    sns.boxplot(bigm_train[feature])\n    plt.title(feature)\n    plt.show()\n\n\n# %% [markdown]\n# Both Item_Visibility and Item_Outlet_Sales have outliers\n\n# %% [markdown]\n# **A- Training data**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:16:22.381931Z\",\"iopub.execute_input\":\"2023-07-05T18:16:22.382348Z\",\"iopub.status.idle\":\"2023-07-05T18:16:22.414746Z\",\"shell.execute_reply.started\":\"2023-07-05T18:16:22.382303Z\",\"shell.execute_reply\":\"2023-07-05T18:16:22.413663Z\"}}\nbigm_train.describe()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:16:25.473922Z\",\"iopub.execute_input\":\"2023-07-05T18:16:25.474301Z\",\"iopub.status.idle\":\"2023-07-05T18:16:25.503866Z\",\"shell.execute_reply.started\":\"2023-07-05T18:16:25.474271Z\",\"shell.execute_reply\":\"2023-07-05T18:16:25.502561Z\"}}\n#ratio of null values in each column\nbigm_train.isnull().sum()/bigm_train.shape[0] *100\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:16:28.743549Z\",\"iopub.execute_input\":\"2023-07-05T18:16:28.743943Z\",\"iopub.status.idle\":\"2023-07-05T18:16:51.530579Z\",\"shell.execute_reply.started\":\"2023-07-05T18:16:28.743914Z\",\"shell.execute_reply\":\"2023-07-05T18:16:51.529427Z\"}}\npp.ProfileReport(bigm_train)\n\n# %% [markdown]\n# **B- Test dataset**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:16:58.114309Z\",\"iopub.execute_input\":\"2023-07-05T18:16:58.115185Z\",\"iopub.status.idle\":\"2023-07-05T18:16:58.142418Z\",\"shell.execute_reply.started\":\"2023-07-05T18:16:58.115150Z\",\"shell.execute_reply\":\"2023-07-05T18:16:58.141643Z\"}}\nbigm_test.describe()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:02.669990Z\",\"iopub.execute_input\":\"2023-07-05T18:17:02.670386Z\",\"iopub.status.idle\":\"2023-07-05T18:17:02.696876Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:02.670325Z\",\"shell.execute_reply\":\"2023-07-05T18:17:02.695768Z\"}}\n#ratio of null values in each column\nbigm_test.isnull().sum()/bigm_test.shape[0] *100\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:06.029845Z\",\"iopub.execute_input\":\"2023-07-05T18:17:06.030225Z\",\"iopub.status.idle\":\"2023-07-05T18:17:24.295823Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:06.030196Z\",\"shell.execute_reply\":\"2023-07-05T18:17:24.294612Z\"}}\npp.ProfileReport(bigm_test)\n\n# %% [markdown]\n# # **6)Univariate Analysis**\n\n# %% [markdown]\n# * **Item_Fat_Content**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:35.862216Z\",\"iopub.execute_input\":\"2023-07-05T18:17:35.862604Z\",\"iopub.status.idle\":\"2023-07-05T18:17:35.872307Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:35.862575Z\",\"shell.execute_reply\":\"2023-07-05T18:17:35.871119Z\"}}\nbigm_train['Item_Fat_Content'].value_counts()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:40.557026Z\",\"iopub.execute_input\":\"2023-07-05T18:17:40.557428Z\",\"iopub.status.idle\":\"2023-07-05T18:17:40.567472Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:40.557394Z\",\"shell.execute_reply\":\"2023-07-05T18:17:40.566310Z\"}}\nbigm_test['Item_Fat_Content'].value_counts()\n\n# %% [markdown]\n# It seems that we need to fix the inconsistencies in this column since we only need two distinct entries: Low Fat and Regular. To do so, we need to replace the other entries with the right values.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:47.060853Z\",\"iopub.execute_input\":\"2023-07-05T18:17:47.061281Z\",\"iopub.status.idle\":\"2023-07-05T18:17:47.076791Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:47.061247Z\",\"shell.execute_reply\":\"2023-07-05T18:17:47.075619Z\"}}\nbigm_train['Item_Fat_Content'].replace(['low fat','LF','reg'],['Low Fat','Low Fat','Regular'],inplace = True)\nbigm_test['Item_Fat_Content'].replace(['low fat','LF','reg'],['Low Fat','Low Fat','Regular'],inplace = True)\n\n# %% [markdown]\n# Now that we fixed the issues of our column, we can visualize our data in a barplot.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:50.424170Z\",\"iopub.execute_input\":\"2023-07-05T18:17:50.424805Z\",\"iopub.status.idle\":\"2023-07-05T18:17:50.665411Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:50.424768Z\",\"shell.execute_reply\":\"2023-07-05T18:17:50.664299Z\"}}\n\nsns.countplot(x='Item_Fat_Content',data=bigm_train)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:54.024668Z\",\"iopub.execute_input\":\"2023-07-05T18:17:54.025155Z\",\"iopub.status.idle\":\"2023-07-05T18:17:54.298552Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:54.025114Z\",\"shell.execute_reply\":\"2023-07-05T18:17:54.297404Z\"}}\nsns.countplot(x='Item_Fat_Content',data=bigm_test)\n\n# %% [markdown]\n# Low fat products are more bought than regular products\n\n# %% [markdown]\n# * **Item_Type**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:17:58.189258Z\",\"iopub.execute_input\":\"2023-07-05T18:17:58.190513Z\",\"iopub.status.idle\":\"2023-07-05T18:17:58.199278Z\",\"shell.execute_reply.started\":\"2023-07-05T18:17:58.190463Z\",\"shell.execute_reply\":\"2023-07-05T18:17:58.198344Z\"}}\nbigm_train.Item_Type.unique()\n\n# %% [markdown]\n# the different items are indeed all unique and there are no inconsistencies. We can proceed to plot the data in order to analyze it.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:01.390972Z\",\"iopub.execute_input\":\"2023-07-05T18:18:01.391394Z\",\"iopub.status.idle\":\"2023-07-05T18:18:02.006067Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:01.391360Z\",\"shell.execute_reply\":\"2023-07-05T18:18:02.004980Z\"}}\nplt.figure(figsize=(25,17))\nsns.countplot(y='Item_Type',data=bigm_train,order = bigm_train['Item_Type'].value_counts().index)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:05.768523Z\",\"iopub.execute_input\":\"2023-07-05T18:18:05.768928Z\",\"iopub.status.idle\":\"2023-07-05T18:18:06.405650Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:05.768897Z\",\"shell.execute_reply\":\"2023-07-05T18:18:06.404418Z\"}}\nplt.figure(figsize=(25,17))\nsns.countplot(y='Item_Type',data=bigm_test,order = bigm_test['Item_Type'].value_counts().index)\n\n# %% [markdown]\n# Fruits&Vegetables and Snack Foods are the most bought item types while Seafood, Breakfast and other non categorized types don't sell much.\n\n# %% [markdown]\n# * **Outlet_Establishment_Year**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:10.400409Z\",\"iopub.execute_input\":\"2023-07-05T18:18:10.400836Z\",\"iopub.status.idle\":\"2023-07-05T18:18:10.408990Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:10.400802Z\",\"shell.execute_reply\":\"2023-07-05T18:18:10.407913Z\"}}\nbigm_train.Outlet_Establishment_Year.unique()\n\n\n# %% [markdown]\n# The outlets were build between 1985 and 2009. let's plot the data to get more info.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:14.034398Z\",\"iopub.execute_input\":\"2023-07-05T18:18:14.035245Z\",\"iopub.status.idle\":\"2023-07-05T18:18:14.352348Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:14.035207Z\",\"shell.execute_reply\":\"2023-07-05T18:18:14.351264Z\"}}\nsns.countplot(data=bigm_train,x='Outlet_Establishment_Year')\n\n# %% [markdown]\n# It seems that the outlets built on 1985 have more items than any other outlets. Likewise, the outlets built on 1998 have less items.\n\n# %% [markdown]\n# * **Outlet_Size**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:18.553153Z\",\"iopub.execute_input\":\"2023-07-05T18:18:18.554316Z\",\"iopub.status.idle\":\"2023-07-05T18:18:18.807119Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:18.554273Z\",\"shell.execute_reply\":\"2023-07-05T18:18:18.805972Z\"}}\nsns.countplot(data=bigm_train,x='Outlet_Size')\n\n# %% [markdown]\n# Most outlets are of Medium size. High size outlets are not that abundant.\n\n# %% [markdown]\n# * **Outlet_Location_Type**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:24.422796Z\",\"iopub.execute_input\":\"2023-07-05T18:18:24.423240Z\",\"iopub.status.idle\":\"2023-07-05T18:18:24.693427Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:24.423204Z\",\"shell.execute_reply\":\"2023-07-05T18:18:24.692291Z\"}}\nsns.countplot(data=bigm_train,x='Outlet_Location_Type')\n\n# %% [markdown]\n# Tier 3 cities contain the most number of outlets.\n\n# %% [markdown]\n# * **Outlet_Type**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:28.351007Z\",\"iopub.execute_input\":\"2023-07-05T18:18:28.351454Z\",\"iopub.status.idle\":\"2023-07-05T18:18:28.625388Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:28.351419Z\",\"shell.execute_reply\":\"2023-07-05T18:18:28.624344Z\"}}\nplt.figure(figsize=(8,5))\nsns.countplot(data=bigm_train,x='Outlet_Type')\n\n# %% [markdown]\n# Supermakets Type 1 are the most built type. There are more than 5000 outlet of Type1 of Supermarkets.\n\n# %% [markdown]\n# * **Item_Outlet_Sales**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:32.441290Z\",\"iopub.execute_input\":\"2023-07-05T18:18:32.441711Z\",\"iopub.status.idle\":\"2023-07-05T18:18:32.449798Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:32.441677Z\",\"shell.execute_reply\":\"2023-07-05T18:18:32.448691Z\"}}\nbigm_train.Item_Outlet_Sales.unique()\n\n# %% [markdown]\n# This column has a high cardinality. We'll use a distribution plot to visualize the data in an efficient way.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:36.547152Z\",\"iopub.execute_input\":\"2023-07-05T18:18:36.547554Z\",\"iopub.status.idle\":\"2023-07-05T18:18:37.234195Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:36.547525Z\",\"shell.execute_reply\":\"2023-07-05T18:18:37.233098Z\"}}\nsns.displot(bigm_train.Item_Outlet_Sales,kde=True)\n\n# %% [markdown]\n# # **7)Bivariate Analysis**\n\n# %% [markdown]\n# Since our target variable is Item_Outlet_Sales, we'll find its correlation to the different other variables. Below is a table showing the correlation between our dependent variables and target variable.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:41.253657Z\",\"iopub.execute_input\":\"2023-07-05T18:18:41.254041Z\",\"iopub.status.idle\":\"2023-07-05T18:18:41.265770Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:41.254012Z\",\"shell.execute_reply\":\"2023-07-05T18:18:41.264535Z\"}}\nnum_features = bigm_train.select_dtypes(include=[np.number])\ncorr=num_features.corr()\ncorr['Item_Outlet_Sales'].sort_values()\n\n# %% [markdown]\n# Item_MRP has the highest positive correlation to Item_Outlet_Sales. Meanwhile, Item_Weight has the lowest correlation rate with the target variable.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:45.318082Z\",\"iopub.execute_input\":\"2023-07-05T18:18:45.318471Z\",\"iopub.status.idle\":\"2023-07-05T18:18:45.741465Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:45.318441Z\",\"shell.execute_reply\":\"2023-07-05T18:18:45.740310Z\"}}\nplt.figure(figsize=(12,7))\nplt.xlabel(\"Item_MRP\")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Item_MRP and Item_Outlet_Sales Analysis\")\nplt.scatter(bigm_train.Item_MRP, bigm_train.Item_Outlet_Sales)\n\n# %% [markdown]\n# The scatterplot shows a positive relationship between the two variables: as the item's maximum retail price increases, the item sales tends to increase as well.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:53.569788Z\",\"iopub.execute_input\":\"2023-07-05T18:18:53.570202Z\",\"iopub.status.idle\":\"2023-07-05T18:18:53.602248Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:53.570168Z\",\"shell.execute_reply\":\"2023-07-05T18:18:53.601097Z\"}}\n#define response variable\ny = bigm_train['Item_Outlet_Sales']\n\n#define explanatory variable\nx = bigm_train['Item_MRP']\n\n#add constant to predictor variables\nx = sm.add_constant(x)\n\n#fit linear regression model\nmodel = sm.OLS(y, x).fit()\n\n#view model summary\nprint(model.summary())\n\n# %% [markdown]\n# The fitted regression equation turns out to be:\n# \n# Item Outlet Sales = 15.5530 * (Item_MRP) - 11.5751 \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:18:59.957047Z\",\"iopub.execute_input\":\"2023-07-05T18:18:59.957470Z\",\"iopub.status.idle\":\"2023-07-05T18:19:00.417025Z\",\"shell.execute_reply.started\":\"2023-07-05T18:18:59.957436Z\",\"shell.execute_reply\":\"2023-07-05T18:19:00.415910Z\"}}\nplt.figure(figsize=[20,9])\nplt.scatter(bigm_train.Item_Visibility,bigm_train.Item_Outlet_Sales)\nplt.xlabel('Item_Visibility')\nplt.ylabel('Item_Outlet_Sales')\n\n# %% [markdown]\n# Low bisibility items sell more than items with high visibility. This isn't surprising since the correlation rate we've found earlier was negative. This result is all logical since items that have high visibility, meaning that they take a lot of space of the display space in the store are less sold and that is because they tend to be pricey products not for everyday use.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:05.980543Z\",\"iopub.execute_input\":\"2023-07-05T18:19:05.980960Z\",\"iopub.status.idle\":\"2023-07-05T18:19:06.010407Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:05.980925Z\",\"shell.execute_reply\":\"2023-07-05T18:19:06.009303Z\"}}\npd.pivot_table(bigm_train,'Item_Outlet_Sales',index='Item_Type',columns='Outlet_Size')\n     \n\n# %% [markdown]\n# By having a look at the table above, we can conclude that medium size outlets have the most sales while small size outlets sell the least.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:09.850632Z\",\"iopub.execute_input\":\"2023-07-05T18:19:09.851053Z\",\"iopub.status.idle\":\"2023-07-05T18:19:10.284185Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:09.851020Z\",\"shell.execute_reply\":\"2023-07-05T18:19:10.283077Z\"}}\nplt.figure(figsize=(12,7))\nplt.xlabel(\"Item_Weight\")\nplt.ylabel(\"Item_Outlet_Sales\")\nplt.title(\"Item_Weight and Item_Outlet_Sales Analysis\")\nplt.scatter(bigm_train.Item_Weight, bigm_train.Item_Outlet_Sales)\n\n# %% [markdown]\n# There seems to be no correlation between the item weight and the sales. An expected result since it shows the same thing in the correlation table.\n\n# %% [markdown]\n# # **8)Missing Value Treatment**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:14.513947Z\",\"iopub.execute_input\":\"2023-07-05T18:19:14.514325Z\",\"iopub.status.idle\":\"2023-07-05T18:19:14.543823Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:14.514295Z\",\"shell.execute_reply\":\"2023-07-05T18:19:14.542704Z\"}}\nbigm_train.isnull().sum()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:17.349548Z\",\"iopub.execute_input\":\"2023-07-05T18:19:17.349927Z\",\"iopub.status.idle\":\"2023-07-05T18:19:17.372143Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:17.349899Z\",\"shell.execute_reply\":\"2023-07-05T18:19:17.371035Z\"}}\nbigm_test.isnull().sum()\n\n# %% [markdown]\n# There seems to be only the same two columns in both training and test sets to have missing values. Let's proceed to clean our datasets and handle those missing values.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:21.656509Z\",\"iopub.execute_input\":\"2023-07-05T18:19:21.657015Z\",\"iopub.status.idle\":\"2023-07-05T18:19:21.686834Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:21.656970Z\",\"shell.execute_reply\":\"2023-07-05T18:19:21.685529Z\"}}\n#Let's try dropping rows with missing values\ntrain=bigm_train.dropna()\ntrain.shape\n\n# %% [markdown]\n# Just by testing the method on our training dataset, it seems like almost half of the information is lost. We'll look for another method.\n\n# %% [markdown]\n# The Item_Weight column is a numerical column while the Outlet_Size is a categorical one. That must gives us an idea as to how to handle the missing values.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:27.890438Z\",\"iopub.execute_input\":\"2023-07-05T18:19:27.890823Z\",\"iopub.status.idle\":\"2023-07-05T18:19:27.907136Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:27.890796Z\",\"shell.execute_reply\":\"2023-07-05T18:19:27.905845Z\"}}\nprint('Training set')\nprint(bigm_train.Item_Weight.describe())\nprint( '\\n')\nprint('Test Set')\nprint(bigm_test.Item_Weight.describe())\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:32.477813Z\",\"iopub.execute_input\":\"2023-07-05T18:19:32.478255Z\",\"iopub.status.idle\":\"2023-07-05T18:19:32.485604Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:32.478205Z\",\"shell.execute_reply\":\"2023-07-05T18:19:32.484658Z\"}}\nbigm_train['Item_Weight'].fillna(bigm_train['Item_Weight'].mean(),inplace=True)  #replacing null values with mean values\nbigm_test['Item_Weight'].fillna(bigm_train['Item_Weight'].mean(),inplace=True)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:35.907374Z\",\"iopub.execute_input\":\"2023-07-05T18:19:35.907757Z\",\"iopub.status.idle\":\"2023-07-05T18:19:35.914718Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:35.907729Z\",\"shell.execute_reply\":\"2023-07-05T18:19:35.913537Z\"}}\nprint(bigm_train.Item_Weight.isnull().sum())\nprint(bigm_test.Item_Weight.isnull().sum())\n\n# %% [markdown]\n# We filled all the missing values with the mean value of the column. Let's check the description of the column after imputation and compare it to the old values.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:39.588772Z\",\"iopub.execute_input\":\"2023-07-05T18:19:39.589195Z\",\"iopub.status.idle\":\"2023-07-05T18:19:39.604544Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:39.589162Z\",\"shell.execute_reply\":\"2023-07-05T18:19:39.603222Z\"}}\nprint('Training set')\nprint(bigm_train.Item_Weight.describe())\nprint( '\\n')\nprint('Test Set')\nprint(bigm_test.Item_Weight.describe())\n\n\n# %% [markdown]\n# The mean is still the same in the training set and changed in an insignificant way in the test set. The other values also didn't change that much. The changes are slitely observed so the imputation was succesfull.\n\n# %% [markdown]\n# Now let's move to the Outlet_Size column. We'll proceed with a mode imputation since we're dealing with a categorical column.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:43.842237Z\",\"iopub.execute_input\":\"2023-07-05T18:19:43.842690Z\",\"iopub.status.idle\":\"2023-07-05T18:19:43.851662Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:43.842652Z\",\"shell.execute_reply\":\"2023-07-05T18:19:43.850695Z\"}}\nprint(bigm_train['Outlet_Size'].mode())\nprint(bigm_test['Outlet_Size'].mode())\n\n# %% [markdown]\n# The column is unimodal so that makes things easier.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:48.094792Z\",\"iopub.execute_input\":\"2023-07-05T18:19:48.095222Z\",\"iopub.status.idle\":\"2023-07-05T18:19:48.106455Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:48.095182Z\",\"shell.execute_reply\":\"2023-07-05T18:19:48.105266Z\"}}\nbigm_train['Outlet_Size'].fillna(bigm_train['Outlet_Size'].mode()[0],inplace=True)\nbigm_test['Outlet_Size'].fillna(bigm_test['Outlet_Size'].mode()[0],inplace=True)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:51.020047Z\",\"iopub.execute_input\":\"2023-07-05T18:19:51.020442Z\",\"iopub.status.idle\":\"2023-07-05T18:19:51.028844Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:51.020413Z\",\"shell.execute_reply\":\"2023-07-05T18:19:51.027661Z\"}}\nprint(bigm_test.Outlet_Size.isnull().sum())\nprint(bigm_train.Outlet_Size.isnull().sum())\n\n# %% [markdown]\n# No more missing values!!\n\n# %% [markdown]\n# # **9)Feature Engineering**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:54.687662Z\",\"iopub.execute_input\":\"2023-07-05T18:19:54.688100Z\",\"iopub.status.idle\":\"2023-07-05T18:19:54.721503Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:54.688064Z\",\"shell.execute_reply\":\"2023-07-05T18:19:54.720676Z\"}}\nbigm_train.info()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:19:58.977623Z\",\"iopub.execute_input\":\"2023-07-05T18:19:58.978045Z\",\"iopub.status.idle\":\"2023-07-05T18:19:58.996913Z\",\"shell.execute_reply.started\":\"2023-07-05T18:19:58.978012Z\",\"shell.execute_reply\":\"2023-07-05T18:19:58.995904Z\"}}\nbigm_train.head()\n\n# %% [markdown]\n# **Item_Fat_Content**\n\n# %% [markdown]\n# For this column, we only have two possibilities: Low Fat or Regular. However, if we look at the item types, there are types that aren't edible meaning they can't be classified as Low Fat or even Regular. And knowing that we don't have any missing values, we can conclude that some inedible items have been mistakenly categorized just like the item in the 5th row above, it is of type Household but is considered as Low Fat which doesn't make sense. \n# \n# We can also see that item identifiers start with either FD(Food),DR(Drinks) or NC(Non Consumable).\n# This said, we should create another category \"Non-Consumable\" for the Item_Fat_Content.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:02.849410Z\",\"iopub.execute_input\":\"2023-07-05T18:20:02.849782Z\",\"iopub.status.idle\":\"2023-07-05T18:20:02.866102Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:02.849754Z\",\"shell.execute_reply\":\"2023-07-05T18:20:02.865288Z\"}}\nbigm_train.loc[bigm_train['Item_Identifier'].str.startswith('NC'), 'Item_Fat_Content'] = 'Non-Consumable'\nbigm_test.loc[bigm_test['Item_Identifier'].str.startswith('NC'), 'Item_Fat_Content'] = 'Non-Consumable'\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:06.786598Z\",\"iopub.execute_input\":\"2023-07-05T18:20:06.787016Z\",\"iopub.status.idle\":\"2023-07-05T18:20:06.798604Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:06.786984Z\",\"shell.execute_reply\":\"2023-07-05T18:20:06.797322Z\"}}\n\nprint('Training set')\nprint(bigm_train.Item_Fat_Content.value_counts())\nprint( '\\n')\nprint('Test Set')\nprint(bigm_test.Item_Fat_Content.value_counts())\n\n\n# %% [markdown]\n# Issue resolved!!\n\n# %% [markdown]\n# **Item_Visibility**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:10.799039Z\",\"iopub.execute_input\":\"2023-07-05T18:20:10.799466Z\",\"iopub.status.idle\":\"2023-07-05T18:20:10.808545Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:10.799433Z\",\"shell.execute_reply\":\"2023-07-05T18:20:10.807047Z\"}}\nn_zeros_train=(((bigm_train.Item_Visibility==0).sum())/bigm_train.shape[0])*100\nprint(\"Zeros rate in the column for training set:\",n_zeros_train,'%')\nn_zeros_test=(((bigm_test.Item_Visibility==0).sum())/bigm_test.shape[0])*100\nprint(\"Zeros rate in the column for test set:\",n_zeros_test,'%')\n\n# %% [markdown]\n# Over 6% of the variables in the Item_Visibility are zeros which doesn't make sense. A product can't have a null visibility.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:14.577900Z\",\"iopub.execute_input\":\"2023-07-05T18:20:14.578322Z\",\"iopub.status.idle\":\"2023-07-05T18:20:14.586310Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:14.578289Z\",\"shell.execute_reply\":\"2023-07-05T18:20:14.585140Z\"}}\nbigm_train['Item_Visibility'].replace(0,bigm_train['Item_Visibility'].mean(),inplace=True)\nbigm_test['Item_Visibility'].replace(0,bigm_test['Item_Visibility'].mean(),inplace=True)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:18.526019Z\",\"iopub.execute_input\":\"2023-07-05T18:20:18.526465Z\",\"iopub.status.idle\":\"2023-07-05T18:20:18.535183Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:18.526432Z\",\"shell.execute_reply\":\"2023-07-05T18:20:18.534215Z\"}}\nn_zeros_train=(((bigm_train.Item_Visibility==0).sum())/bigm_train.shape[0])*100\nprint(\"Zeros rate in the column for training set:\",n_zeros_train,'%')\nn_zeros_test=(((bigm_test.Item_Visibility==0).sum())/bigm_test.shape[0])*100\nprint(\"Zeros rate in the column for test set:\",n_zeros_test,'%')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:22.034959Z\",\"iopub.execute_input\":\"2023-07-05T18:20:22.035392Z\",\"iopub.status.idle\":\"2023-07-05T18:20:22.492554Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:22.035323Z\",\"shell.execute_reply\":\"2023-07-05T18:20:22.491535Z\"}}\nplt.figure(figsize=[20,9])\nplt.scatter(bigm_train.Item_Visibility,bigm_train.Item_Outlet_Sales)\nplt.xlabel('Item_Visibility')\nplt.ylabel('Item_Outlet_Sales')\n\n# %% [markdown]\n# The negative correlation is more enhanced\n\n# %% [markdown]\n# **Outlet_Establishmen_Year**\n\n# %% [markdown]\n# Since we know that the data is from 2013, we can create a new feature **Outlet_Operation_Years** that gives us for how many years the outlets are operating.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:38.394862Z\",\"iopub.execute_input\":\"2023-07-05T18:20:38.395261Z\",\"iopub.status.idle\":\"2023-07-05T18:20:38.402587Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:38.395230Z\",\"shell.execute_reply\":\"2023-07-05T18:20:38.401487Z\"}}\nbigm_train['Outlet_Operation_Years'] = 2013 - bigm_train['Outlet_Establishment_Year']\nbigm_test['Outlet_Operation_Years'] = 2013 - bigm_test['Outlet_Establishment_Year']\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:41.883905Z\",\"iopub.execute_input\":\"2023-07-05T18:20:41.884274Z\",\"iopub.status.idle\":\"2023-07-05T18:20:41.895623Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:41.884247Z\",\"shell.execute_reply\":\"2023-07-05T18:20:41.894635Z\"}}\nbigm_train['Outlet_Operation_Years'].describe()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:44.428591Z\",\"iopub.execute_input\":\"2023-07-05T18:20:44.429518Z\",\"iopub.status.idle\":\"2023-07-05T18:20:44.440513Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:44.429480Z\",\"shell.execute_reply\":\"2023-07-05T18:20:44.439527Z\"}}\nbigm_test['Outlet_Operation_Years'].describe()\n\n# %% [markdown]\n# **Item_Type**\n\n# %% [markdown]\n# As we can see, the Item_Type fature has a high cardinality so using one hot encoding later on it would not be a good idea. This said, we suggest adding a new feature that splits the items into 3 categories: 'Food', 'Drinks' and 'Non-Consumable'.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:48.443801Z\",\"iopub.execute_input\":\"2023-07-05T18:20:48.444320Z\",\"iopub.status.idle\":\"2023-07-05T18:20:48.458262Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:48.444277Z\",\"shell.execute_reply\":\"2023-07-05T18:20:48.456769Z\"}}\nbigm_train['New_Item_Type'] = bigm_train['Item_Identifier'].apply(lambda x: x[:2])\nbigm_train['New_Item_Type'] = bigm_train['New_Item_Type'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'})\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:53.560114Z\",\"iopub.execute_input\":\"2023-07-05T18:20:53.560500Z\",\"iopub.status.idle\":\"2023-07-05T18:20:53.572586Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:53.560470Z\",\"shell.execute_reply\":\"2023-07-05T18:20:53.571572Z\"}}\nbigm_test['New_Item_Type'] = bigm_test['Item_Identifier'].apply(lambda x: x[:2])\nbigm_test['New_Item_Type'] = bigm_test['New_Item_Type'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'})\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:20:59.179665Z\",\"iopub.execute_input\":\"2023-07-05T18:20:59.180096Z\",\"iopub.status.idle\":\"2023-07-05T18:20:59.201812Z\",\"shell.execute_reply.started\":\"2023-07-05T18:20:59.180060Z\",\"shell.execute_reply\":\"2023-07-05T18:20:59.200499Z\"}}\nbigm_train.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:02.455950Z\",\"iopub.execute_input\":\"2023-07-05T18:21:02.456627Z\",\"iopub.status.idle\":\"2023-07-05T18:21:02.463363Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:02.456590Z\",\"shell.execute_reply\":\"2023-07-05T18:21:02.462243Z\"}}\nbigm_test.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:05.716556Z\",\"iopub.execute_input\":\"2023-07-05T18:21:05.716924Z\",\"iopub.status.idle\":\"2023-07-05T18:21:05.723760Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:05.716898Z\",\"shell.execute_reply\":\"2023-07-05T18:21:05.722677Z\"}}\nbigm_train.shape\n\n# %% [markdown]\n# # **10-11)Encoding Categorical Variables (Label Encoding)**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:08.938083Z\",\"iopub.execute_input\":\"2023-07-05T18:21:08.938475Z\",\"iopub.status.idle\":\"2023-07-05T18:21:08.958816Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:08.938446Z\",\"shell.execute_reply\":\"2023-07-05T18:21:08.957757Z\"}}\nbigm_train.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:11.950501Z\",\"iopub.execute_input\":\"2023-07-05T18:21:11.951014Z\",\"iopub.status.idle\":\"2023-07-05T18:21:12.003557Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:11.950961Z\",\"shell.execute_reply\":\"2023-07-05T18:21:12.002278Z\"}}\nlencoder = LabelEncoder()\n# Training Set\nfor i in (2,4,8,9,10,13):\n    bigm_train.iloc[:,i] = lencoder.fit_transform(bigm_train.iloc[:,i])\n# Test set\nfor i in (2,4,8,9,10,12):\n    bigm_test.iloc[:,i] = lencoder.fit_transform(bigm_test.iloc[:,i])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:17.067712Z\",\"iopub.execute_input\":\"2023-07-05T18:21:17.068098Z\",\"iopub.status.idle\":\"2023-07-05T18:21:17.078170Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:17.068070Z\",\"shell.execute_reply\":\"2023-07-05T18:21:17.077055Z\"}}\n# Checking the Unique values for categorical data after label encoding\nprint(\"Item_Fat_Content\\n \",bigm_train.Item_Fat_Content.unique())\nprint(\"Outlet_Size\\n \",bigm_train.Outlet_Size.unique())\nprint(\"Outlet_Location_Type\\n \",bigm_train.Outlet_Location_Type.unique())\nprint(\"Item_Type\\n \",bigm_train.Item_Type.unique())\nprint(\"New_Item_Type\\n \",bigm_train.New_Item_Type.unique())\nprint(\"Outlet_Type\\n \",bigm_train.Outlet_Type.unique())\n\n# %% [markdown]\n# # **12)One Hot Encoding**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:21.567529Z\",\"iopub.execute_input\":\"2023-07-05T18:21:21.567939Z\",\"iopub.status.idle\":\"2023-07-05T18:21:21.576849Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:21.567910Z\",\"shell.execute_reply\":\"2023-07-05T18:21:21.575655Z\"}}\nbigm_train.dtypes\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:24.954830Z\",\"iopub.execute_input\":\"2023-07-05T18:21:24.955236Z\",\"iopub.status.idle\":\"2023-07-05T18:21:24.962619Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:24.955203Z\",\"shell.execute_reply\":\"2023-07-05T18:21:24.961552Z\"}}\nbigm_test.columns\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:28.553325Z\",\"iopub.execute_input\":\"2023-07-05T18:21:28.553732Z\",\"iopub.status.idle\":\"2023-07-05T18:21:28.573177Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:28.553703Z\",\"shell.execute_reply\":\"2023-07-05T18:21:28.571815Z\"}}\nbigm_train = pd.get_dummies(bigm_train, columns=['Item_Fat_Content','Outlet_Type','New_Item_Type'])\nbigm_test = pd.get_dummies(bigm_test, columns=['Item_Fat_Content','Outlet_Type','New_Item_Type'])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:31.799703Z\",\"iopub.execute_input\":\"2023-07-05T18:21:31.800140Z\",\"iopub.status.idle\":\"2023-07-05T18:21:31.807615Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:31.800108Z\",\"shell.execute_reply\":\"2023-07-05T18:21:31.806469Z\"}}\nbigm_test.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:34.789853Z\",\"iopub.execute_input\":\"2023-07-05T18:21:34.790268Z\",\"iopub.status.idle\":\"2023-07-05T18:21:34.798630Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:34.790235Z\",\"shell.execute_reply\":\"2023-07-05T18:21:34.797421Z\"}}\nbigm_test.columns\n\n# %% [markdown]\n# # **13)PreProcessing Data**\n\n# %% [markdown]\n# We start first by removing outliers from the Item_Visibility and Item_Outlet_Sales columns.\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:40.595059Z\",\"iopub.execute_input\":\"2023-07-05T18:21:40.595464Z\",\"iopub.status.idle\":\"2023-07-05T18:21:40.612705Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:40.595433Z\",\"shell.execute_reply\":\"2023-07-05T18:21:40.611410Z\"}}\nscaler = StandardScaler()\n\ncolumns = scaler.fit_transform(bigm_train[['Item_Outlet_Sales', 'Item_Visibility']])\n\nz_scores = np.abs(columns)\n\nz_score_threshold = 2.5\n\noutliers = np.where(z_scores > z_score_threshold)\n\nsamples_with_outliers = set(outliers[0])\nprint(\"Original data shape:\", bigm_train.shape)\nbigm_train = bigm_train.drop(samples_with_outliers)\nprint(\"Data shape after removing outliers:\", bigm_train.shape)\n\n\n# %% [markdown]\n# We can drop some columns as they contribute nothing to the sales like the 'Item_Identifier'and 'Outlet_Identifier'. The 'Outlet_Establishment_Year' can be dropped too as we created another feature 'Outlet_Operation_Years' that serves the same purpose. \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T19:08:19.538014Z\",\"iopub.execute_input\":\"2023-07-05T19:08:19.538468Z\",\"iopub.status.idle\":\"2023-07-05T19:08:19.547719Z\",\"shell.execute_reply.started\":\"2023-07-05T19:08:19.538433Z\",\"shell.execute_reply\":\"2023-07-05T19:08:19.546429Z\"}}\nX = bigm_train.drop(columns=['Outlet_Establishment_Year', 'Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales'])\ny = bigm_train['Item_Outlet_Sales']\nX_test= bigm_test.drop(columns=['Outlet_Establishment_Year', 'Item_Identifier', 'Outlet_Identifier'])\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:51.637869Z\",\"iopub.execute_input\":\"2023-07-05T18:21:51.638283Z\",\"iopub.status.idle\":\"2023-07-05T18:21:51.647426Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:51.638251Z\",\"shell.execute_reply\":\"2023-07-05T18:21:51.646064Z\"}}\n# Split the dataset into training and test sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=22)\n\n# %% [markdown]\n# # **14)Modeling**\n\n# %% [markdown]\n#  **A)Linear Regression**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:55.291946Z\",\"iopub.execute_input\":\"2023-07-05T18:21:55.292392Z\",\"iopub.status.idle\":\"2023-07-05T18:21:55.306426Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:55.292357Z\",\"shell.execute_reply\":\"2023-07-05T18:21:55.304922Z\"}}\nlr= LinearRegression()\nmodel_lr=lr.fit(X_train,y_train)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:21:58.859176Z\",\"iopub.execute_input\":\"2023-07-05T18:21:58.859582Z\",\"iopub.status.idle\":\"2023-07-05T18:21:58.869618Z\",\"shell.execute_reply.started\":\"2023-07-05T18:21:58.859551Z\",\"shell.execute_reply\":\"2023-07-05T18:21:58.868283Z\"}}\ny_pred_lr=lr.predict(X_valid)\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:22:02.294214Z\",\"iopub.execute_input\":\"2023-07-05T18:22:02.294659Z\",\"iopub.status.idle\":\"2023-07-05T18:22:02.494977Z\",\"shell.execute_reply.started\":\"2023-07-05T18:22:02.294622Z\",\"shell.execute_reply\":\"2023-07-05T18:22:02.493804Z\"}}\ncv_score_lr = cross_val_score(model_lr, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\ncv_score_lr = np.abs(np.mean(cv_score_lr))\n    \nprint(\"Model Report\")\nprint(\"MSE:\",mean_squared_error(y_valid,y_pred_lr))\nprint(\"MAE:\",mean_absolute_error(y_valid,y_pred_lr))\nprint(\"CV Score:\", cv_score_lr)   \n\n# %% [markdown]\n#  **B)Regularized Linear Regression**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:22:57.773581Z\",\"iopub.execute_input\":\"2023-07-05T18:22:57.774061Z\",\"iopub.status.idle\":\"2023-07-05T18:22:57.866390Z\",\"shell.execute_reply.started\":\"2023-07-05T18:22:57.774018Z\",\"shell.execute_reply\":\"2023-07-05T18:22:57.865281Z\"}}\n# Initialize the Ridge regression model\nridge = Ridge(alpha=0.7)  # Adjust the alpha value as needed\n\n# Fit the model on the training data\nmodel_ridge=ridge.fit(X_train, y_train)\n\n# Make predictions on the test data\ny_pred_ridge = ridge.predict(X_valid)\n\ncv_score_ridge = cross_val_score(model_ridge, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\ncv_score_ridge= np.abs(np.mean(cv_score_ridge))\n    \nprint(\"Model Report\")\nprint(\"MSE:\",mean_squared_error(y_valid,y_pred_ridge))\nprint(\"MAE:\",mean_absolute_error(y_valid,y_pred_ridge))\nprint(\"CV Score:\", cv_score_ridge)   \n\n\n# %% [markdown]\n#  **C)RandomForest**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:33:05.255750Z\",\"iopub.execute_input\":\"2023-07-05T18:33:05.256153Z\",\"iopub.status.idle\":\"2023-07-05T18:41:05.382470Z\",\"shell.execute_reply.started\":\"2023-07-05T18:33:05.256121Z\",\"shell.execute_reply\":\"2023-07-05T18:41:05.381203Z\"}}\n# Define the parameter grid for Random Forest\nparam_grid_rf = {\n    'n_estimators': [100, 200, 300],  # Adjust the number of estimators as needed\n    'max_depth': [None, 5, 10],  # Adjust the maximum depth as needed\n    'min_samples_split': [2, 5, 10]  # Adjust the minimum samples split as needed\n}\n# Initialize the Random Forest regression model\nrf = RandomForestRegressor(random_state=42)  # Adjust the number of estimators as needed\n\n# Perform grid search to find the best parameters\ngrid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error')\ngrid_search_rf.fit(X_train, y_train)\n\n# Get the best model and its parameters\nbest_model_rf = grid_search_rf.best_estimator_\nbest_params_rf = grid_search_rf.best_params_\n\n\n# Make predictions on the test data\ny_pred_rf = best_model_rf.predict(X_valid)\n\ncv_score_rf = cross_val_score(model_rf, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\ncv_score_rf= np.abs(np.mean(cv_score_rf))\n    \nprint(\"Model Report\")\nprint(\"MSE:\",mean_squared_error(y_valid,y_pred_rf))\nprint(\"MAE:\",mean_absolute_error(y_valid,y_pred_rf))\nprint(\"CV Score:\", cv_score_rf)   \n\n\n# %% [markdown]\n#  **D)XGBoost**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T18:43:03.851050Z\",\"iopub.execute_input\":\"2023-07-05T18:43:03.852464Z\",\"iopub.status.idle\":\"2023-07-05T18:44:56.490271Z\",\"shell.execute_reply.started\":\"2023-07-05T18:43:03.852416Z\",\"shell.execute_reply\":\"2023-07-05T18:44:56.489401Z\"}}\n# Define the parameter grid for XGBoost\nparam_grid_xgb = {\n    'n_estimators': [100, 200, 300],  # Adjust the number of estimators as needed\n    'max_depth': [3, 5, 7],  # Adjust the maximum depth as needed\n    'learning_rate': [0.1, 0.01, 0.001]  # Adjust the learning rate as needed\n}\n\n# Initialize the XGBoost regression model\nxgb = XGBRegressor(random_state=42)\n\n# Perform grid search to find the best parameters\ngrid_search_xgb = GridSearchCV(xgb, param_grid_xgb, cv=5, scoring='neg_mean_squared_error')\ngrid_search_xgb.fit(X_train, y_train)\n\n# Get the best model and its parameters\nbest_model_xgb = grid_search_xgb.best_estimator_\nbest_params_xgb = grid_search_xgb.best_params_\n\n# Make predictions on the test data using the best model\ny_pred_xgb = best_model_xgb.predict(X_valid)\n\ncv_score_xgb = cross_val_score(model_xgb, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\ncv_score_xgb= np.abs(np.mean(cv_score_xgb))\n    \nprint(\"Model Report\")\nprint(\"MSE:\",mean_squared_error(y_valid,y_pred_xgb))\nprint(\"MAE:\",mean_absolute_error(y_valid,y_pred_xgb))\nprint(\"CV Score:\", cv_score_xgb)   \n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T19:00:57.227304Z\",\"iopub.execute_input\":\"2023-07-05T19:00:57.227773Z\",\"iopub.status.idle\":\"2023-07-05T19:00:57.238781Z\",\"shell.execute_reply.started\":\"2023-07-05T19:00:57.227741Z\",\"shell.execute_reply\":\"2023-07-05T19:00:57.237572Z\"}}\nprint(\"Linear regression               MAE:\",mean_absolute_error(y_valid,y_pred_lr), \"/    CV Score:\",cv_score_lr)\nprint(\"Regularised linear regression   MAE:\",mean_absolute_error(y_valid,y_pred_ridge), \"/    CV Score:\",cv_score_ridge)\nprint(\"Random Forest                   MAE:\",mean_absolute_error(y_valid,y_pred_rf), \"/    CV Score:\",cv_score_rf)\nprint(\"XGBoost                         MAE:\",mean_absolute_error(y_valid,y_pred_xgb), \"/    CV Score:\",cv_score_xgb)\n\n# %% [markdown]\n# # **15)Summary**\n\n# %% [markdown]\n# Judging from the results above, we can conclude that the best combination of MAE and CV score is that obtained by using the XGBoost model. So we'll be using it to predict the sales later.\n\n# %% [markdown]\n# # **Predictions on Test Set**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T19:09:22.165366Z\",\"iopub.execute_input\":\"2023-07-05T19:09:22.166608Z\",\"iopub.status.idle\":\"2023-07-05T19:09:22.194154Z\",\"shell.execute_reply.started\":\"2023-07-05T19:09:22.166565Z\",\"shell.execute_reply\":\"2023-07-05T19:09:22.193298Z\"}}\n\nbigm_test_identifiers =pd.DataFrame(bigm_test[['Item_Identifier', 'Outlet_Identifier']])\nbigm_test_predictions =pd.DataFrame(best_model_xgb.predict(X_test), columns=['Item_Outlet_Sales'])\n\nfinal_result = pd.concat([bigm_test_identifiers,bigm_test_predictions], axis=1)\nfinal_result\n\n\n# %% [markdown]\n# # **Saving The Test Predictions**\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-07-05T19:12:20.084081Z\",\"iopub.execute_input\":\"2023-07-05T19:12:20.084489Z\",\"iopub.status.idle\":\"2023-07-05T19:12:20.120758Z\",\"shell.execute_reply.started\":\"2023-07-05T19:12:20.084457Z\",\"shell.execute_reply\":\"2023-07-05T19:12:20.119636Z\"}}\nfinal_result.to_csv('bigm_test_predictions.csv')","metadata":{"_uuid":"71af9b63-e7ca-4459-a019-529b6f6a001c","_cell_guid":"a5d0ae47-101b-49f1-b991-7b6f29906561","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}